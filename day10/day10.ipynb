{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "announced-funds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[({(<(())[]>[[{[]{<()<>>',\n",
       " '[(()[<>])]({[<{<<[]>>(',\n",
       " '{([(<{}[<>[]}>{[]{[(<()>',\n",
       " '(((({<>}<{<{<>}{[]{[]{}',\n",
       " '[[<[([]))<([[{}[[()]]]',\n",
       " '[{[{({}]{}}([{[{{{}}([]',\n",
       " '{<[[]]>}<{[{[{[]{()[[[]',\n",
       " '[<(<(<(<{}))><([]([]()',\n",
       " '<{([([[(<>()){}]>(<<{{',\n",
       " '<{([{{}}[<[[[<>{}]]]>[]]']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_lines(filename):\n",
    "    lines = []\n",
    "    with open(filename, \"r\") as fh:\n",
    "        for l in fh:\n",
    "            lines.append(l.strip())\n",
    "    return lines\n",
    "\n",
    "test = read_lines(\"test.txt\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bibliographic-survey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{')': '(',\n",
       " '(': ')',\n",
       " ']': '[',\n",
       " '[': ']',\n",
       " '}': '{',\n",
       " '{': '}',\n",
       " '>': '<',\n",
       " '<': '>'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match = dict()\n",
    "for c in [\"()\", \"[]\", \"{}\", \"<>\"]:\n",
    "    match[c[1]] = c[0]\n",
    "    match[c[0]] = c[1]\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "varied-house",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{')': 3, ']': 57, '}': 1197, '>': 25137}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_score = {')': 3, ']': 57, '}': 1197, '>': 25137}\n",
    "error_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "latin-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({(<(())[]>[[{[]{<()<>>  0\n",
      "[(()[<>])]({[<{<<[]>>(    0\n",
      "{([(<{}[<>[]}>{[]{[(<()>  1197\n",
      "(((({<>}<{<{<>}{[]{[]{}   0\n",
      "[[<[([]))<([[{}[[()]]]    3\n",
      "[{[{({}]{}}([{[{{{}}([]   57\n",
      "{<[[]]>}<{[{[{[]{()[[[]   0\n",
      "[<(<(<(<{}))><([]([]()    3\n",
      "<{([([[(<>()){}]>(<<{{    25137\n",
      "<{([{{}}[<[[[<>{}]]]>[]]  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26397"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse(line):\n",
    "    stack = []\n",
    "    template = \"Expected '{}', got '{}'\"\n",
    "    for c in line:\n",
    "        if c in \"[({<\":\n",
    "            stack.append(c)\n",
    "        elif c in \"])}>\":\n",
    "            if stack[-1] == match[c]:\n",
    "                stack.pop()\n",
    "            else:\n",
    "                return error_score[c], stack\n",
    "    return 0, stack\n",
    "\n",
    "def calc_error_score(lines, debug=False):\n",
    "    total_score = 0\n",
    "    for l in lines:\n",
    "        score, stack = parse(l)\n",
    "        if debug: print(\"{:25s} {}\".format(l, score))\n",
    "        total_score += score\n",
    "    return total_score\n",
    "\n",
    "calc_error_score(test, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "figured-party",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390993"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = read_lines(\"input.txt\")\n",
    "calc_error_score(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fluid-preserve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({(<(())[]>[[{[]{<()<>> }}]])})] 288957\n",
      "[(()[<>])]({[<{<<[]>>( )}>]}) 5566\n",
      "(((({<>}<{<{<>}{[]{[]{} }}>}>)))) 1480781\n",
      "{<[[]]>}<{[{[{[]{()[[[] ]]}}]}]}> 995444\n",
      "<{([{{}}[<[[[<>{}]]]>[]] ])}> 294\n",
      "[294, 5566, 288957, 995444, 1480781]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "288957"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_score = {\n",
    "    ')': 1,\n",
    "    ']': 2,\n",
    "    '}': 3,\n",
    "    '>': 4\n",
    "}\n",
    "\n",
    "def calc_incomplete_score(line, debug=False):\n",
    "    error, stack = parse(line)\n",
    "    if error == 0:\n",
    "        score = 0\n",
    "        complete = \"\"\n",
    "        for c in reversed(stack):\n",
    "            mc = match[c]\n",
    "            complete += mc\n",
    "            score = score * 5 + complete_score[mc]\n",
    "        return score, complete\n",
    "    else:\n",
    "        return None, \"\"\n",
    "    \n",
    "def calc_incomplete_score_all(lines, debug=False):\n",
    "    scores = []\n",
    "    for line in lines:\n",
    "        score, complete = calc_incomplete_score(line, debug)\n",
    "        if score is not None:\n",
    "            if debug: print(\"{} {} {}\".format(line, complete, score))\n",
    "            scores.append(score)\n",
    "    scores = sorted(scores)\n",
    "    if debug: print(scores)\n",
    "    return scores[len(scores)//2]\n",
    "\n",
    "calc_incomplete_score_all(test, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "scientific-saudi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2391385187"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_incomplete_score_all(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-tackle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
